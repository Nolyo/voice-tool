# Voice Tool - Sp√©cification de Migration vers Tauri

## üìã Contexte et Motivation

### Probl√®mes de la Stack Actuelle (Python)

**Technologies probl√©matiques:**
- **Tkinter**: Interface vieillotte, difficile √† styliser, bugs de threading
- **pynput**: Gestion basique des hotkeys, instable
- **sounddevice**: API bas niveau, crashs PortAudio fr√©quents (surtout √† la r√©ouverture de fen√™tres)
- **pystray**: Limit√©, maintenu sporadiquement
- **Threading Python**: Complexit√© excessive (Tk vs pystray vs audio), races conditions
- **PyInstaller**: Exe lourd (80-150 MB), startup lent (2-4s), pas de hot-reload en dev

**Probl√®mes architecturaux:**
- Code monolithique (main.py > 1500 lignes)
- Couplage fort entre UI et logique m√©tier
- Gestion manuelle du multi-threading fragile
- Crashes PortAudio lors manipulation des fen√™tres Tkinter
- Pas de hot-reload en d√©veloppement

**Probl√®mes de transcription:**
- OpenAI Whisper API lent (2-4s pour 10s d'audio)
- Pas de streaming temps r√©el (impossible de voir le texte d√©filer pendant qu'on parle)
- Co√ªt r√©current ($0.006/min)
- D√©pendance r√©seau obligatoire

### Objectifs de la Migration

‚úÖ **UI moderne et professionnelle** - React + Tailwind + shadcn/ui
‚úÖ **Performance** - Exe l√©ger (5-50 MB), startup instantan√© (<1s)
‚úÖ **Transcription rapide** - Whisper local (0.5-1s) + option streaming temps r√©el
‚úÖ **Architecture propre** - S√©paration frontend/backend, code maintenable
‚úÖ **DX am√©lior√©e** - Hot-reload, DevTools, TypeScript
‚úÖ **Distribution simple** - .exe standalone + .msi installer

---

## üéØ Stack Technique Cible

### Frontend
- **Framework**: React 18 + TypeScript
- **Build**: Vite (hot-reload ultra-rapide)
- **UI**: Tailwind CSS + shadcn/ui (composants modernes)
- **State**: Zustand (gestion d'√©tat simple)
- **Icons**: Lucide React
- **Animations**: Framer Motion (optionnel)

### Backend
- **Runtime**: Tauri 2.x (Rust)
- **Audio Capture**: cpal (cross-platform audio library)
- **Hotkeys**: global-hotkey (gestion native)
- **System Tray**: tauri-plugin-system-tray
- **HTTP Client**: reqwest (pour appels API)

### Transcription (Architecture Hybride)
- **Mode 1 (D√©faut)**: API Streaming (Deepgram) - Temps r√©el, aucun t√©l√©chargement
- **Mode 2 (Optionnel)**: Whisper.cpp local - Rapide, gratuit, offline
- **Mode 3 **: Whisper API (optionnel, legacy)

---

## üé§ Architecture de Transcription (C≈ìur du Syst√®me)

### Principe de Fonctionnement

**Par d√©faut (Premier lancement):**
1. L'exe embarque uniquement le binaire `whisper.cpp` (3 MB) - AUCUN mod√®le IA
2. Mode actif: **Deepgram Streaming API**
3. Aucun t√©l√©chargement requis, fonctionne imm√©diatement

**Activation du mode local (√† la demande):**
1. L'utilisateur va dans Settings ‚Üí Transcription
2. S√©lectionne "Mode Local (Offline)"
3. Choix du mod√®le: Tiny (39 MB) / Base (74 MB) / Small (244 MB)
4. Clic sur "T√©l√©charger" ‚Üí Progress bar
5. Mod√®le stock√© dans `%APPDATA%\VoiceTool\models\`
6. Bascule automatique vers whisper.cpp local

**Bascule entre modes:**
- Switch dans l'UI (Settings)
- Passage imm√©diat d'un mode √† l'autre
- Pr√©f√©rence sauvegard√©e dans `user_settings.json`

### Comparaison des Modes

| Crit√®re | Deepgram Streaming (D√©faut) | Whisper.cpp Local (Optionnel) |
|---------|----------------------------|-------------------------------|
| **T√©l√©chargement initial** | Aucun | 39-244 MB (mod√®le IA) |
| **Vitesse** | Temps r√©el (streaming) | 0.5-1s apr√®s enregistrement |
| **Latence** | 100-300ms | N/A (post-traitement) |
| **Streaming live** | ‚úÖ Oui (texte d√©file pendant l'enregistrement) | ‚ùå Non (traitement apr√®s) |
| **Qualit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellente | ‚≠ê‚≠ê‚≠ê‚≠ê(tiny) √† ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê(small) |
| **Co√ªt** | $0.0043/min (~5‚Ç¨/mois usage normal) | GRATUIT |
| **Offline** | ‚ùå N√©cessite internet | ‚úÖ Fonctionne offline |
| **Langues** | 30+ langues | 90+ langues |
| **Privacy** | Audio envoy√© au cloud | 100% local |

### Configuration Technique

#### Deepgram Streaming (Mode D√©faut)

**Fonctionnement:**
1. Connexion WebSocket vers `wss://api.deepgram.com/v1/listen`
2. Envoi de chunks audio en temps r√©el (pendant l'enregistrement)
3. R√©ception de transcriptions partielles (`interim_results`) + finales
4. Affichage live dans l'UI

**Impl√©mentation Rust:**
```rust
// src-tauri/src/transcription/deepgram.rs

use tokio_tungstenite::{connect_async, tungstenite::Message};
use futures_util::{SinkExt, StreamExt};

pub struct DeepgramStreaming {
    websocket: WebSocketStream,
    api_key: String,
}

impl DeepgramStreaming {
    pub async fn connect(&mut self) -> Result<()> {
        let url = format!(
            "wss://api.deepgram.com/v1/listen?language=fr&punctuate=true&interim_results=true",
        );

        let (ws_stream, _) = connect_async(&url).await?;
        self.websocket = ws_stream;

        // Auth header
        self.websocket.send(Message::Text(
            format!("Authorization: Token {}", self.api_key)
        )).await?;

        Ok(())
    }

    pub async fn send_audio(&mut self, audio_chunk: Vec<i16>) -> Result<()> {
        // Convertir en bytes
        let bytes: Vec<u8> = audio_chunk.iter()
            .flat_map(|s| s.to_le_bytes())
            .collect();

        self.websocket.send(Message::Binary(bytes)).await?;
        Ok(())
    }

    pub async fn receive_transcription(&mut self) -> Result<TranscriptResult> {
        if let Some(msg) = self.websocket.next().await {
            let data = msg?;
            let json: DeepgramResponse = serde_json::from_str(&data.to_string())?;

            Ok(TranscriptResult {
                text: json.channel.alternatives[0].transcript.clone(),
                is_final: json.is_final,
            })
        } else {
            Err(anyhow!("Connection closed"))
        }
    }
}
```

**Tauri Command (expos√© au frontend):**
```rust
#[tauri::command]
async fn start_streaming_transcription(
    state: State<'_, AppState>,
    language: String,
) -> Result<(), String> {
    let mut deepgram = state.deepgram.lock().await;
    deepgram.connect().await.map_err(|e| e.to_string())?;

    // Spawner un thread pour recevoir les transcriptions
    tokio::spawn(async move {
        loop {
            match deepgram.receive_transcription().await {
                Ok(result) => {
                    // √âmettre vers le frontend
                    if result.is_final {
                        emit_event("transcription-final", result.text);
                    } else {
                        emit_event("transcription-interim", result.text);
                    }
                }
                Err(e) => {
                    eprintln!("Streaming error: {}", e);
                    break;
                }
            }
        }
    });

    Ok(())
}

#[tauri::command]
fn send_audio_chunk(
    state: State<'_, AppState>,
    chunk: Vec<i16>,
) -> Result<(), String> {
    let deepgram = state.deepgram.lock().await;
    deepgram.send_audio(chunk).await.map_err(|e| e.to_string())
}
```

#### Whisper.cpp Local (Mode Optionnel)

**Fonctionnement:**
1. Mod√®le IA t√©l√©charg√© une seule fois (stock√© dans AppData)
2. Transcription locale apr√®s arr√™t de l'enregistrement
3. Traitement ultra-rapide (0.5-1s)
4. Zero d√©pendance r√©seau

**Impl√©mentation Rust:**
```rust
// src-tauri/src/transcription/whisper.rs

use whisper_rs::{WhisperContext, WhisperContextParameters, FullParams, SamplingStrategy};
use std::path::PathBuf;

pub struct WhisperLocal {
    context: Option<WhisperContext>,
    model_path: PathBuf,
}

impl WhisperLocal {
    pub fn new(model_path: PathBuf) -> Result<Self> {
        let ctx = WhisperContext::new_with_params(
            model_path.to_str().unwrap(),
            WhisperContextParameters::default()
        )?;

        Ok(Self {
            context: Some(ctx),
            model_path,
        })
    }

    pub fn transcribe(&mut self, audio_data: &[f32], language: &str) -> Result<String> {
        let ctx = self.context.as_ref().ok_or(anyhow!("Context not loaded"))?;

        let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });
        params.set_language(Some(language)); // "fr", "en", etc.
        params.set_translate(false);
        params.set_print_special(false);
        params.set_print_progress(false);
        params.set_print_realtime(false);
        params.set_print_timestamps(false);

        // Transcription
        ctx.full(params, audio_data)?;

        // R√©cup√©rer le texte
        let num_segments = ctx.full_n_segments()?;
        let mut full_text = String::new();

        for i in 0..num_segments {
            let segment = ctx.full_get_segment_text(i)?;
            full_text.push_str(&segment);
        }

        Ok(full_text.trim().to_string())
    }
}
```

**Tauri Commands:**
```rust
#[tauri::command]
async fn download_whisper_model(
    app: AppHandle,
    model_size: String, // "tiny", "base", "small"
) -> Result<(), String> {
    let app_data = app.path_resolver()
        .app_data_dir()
        .ok_or("Failed to get app data dir")?;

    let models_dir = app_data.join("models");
    std::fs::create_dir_all(&models_dir).map_err(|e| e.to_string())?;

    let model_filename = format!("ggml-{}.bin", model_size);
    let model_path = models_dir.join(&model_filename);

    // Si d√©j√† t√©l√©charg√©, skip
    if model_path.exists() {
        return Ok(());
    }

    // URL HuggingFace
    let url = format!(
        "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/{}",
        model_filename
    );

    // T√©l√©chargement avec progress
    let client = reqwest::Client::new();
    let response = client.get(&url).send().await.map_err(|e| e.to_string())?;
    let total_size = response.content_length().unwrap_or(0);

    let mut file = std::fs::File::create(&model_path).map_err(|e| e.to_string())?;
    let mut downloaded: u64 = 0;
    let mut stream = response.bytes_stream();

    while let Some(chunk) = stream.next().await {
        let chunk = chunk.map_err(|e| e.to_string())?;
        file.write_all(&chunk).map_err(|e| e.to_string())?;

        downloaded += chunk.len() as u64;
        let progress = (downloaded as f64 / total_size as f64 * 100.0) as u32;

        // √âmettre progress vers frontend
        app.emit_all("download-progress", progress).ok();
    }

    Ok(())
}

#[tauri::command]
async fn transcribe_with_whisper(
    state: State<'_, AppState>,
    audio_data: Vec<f32>,
    language: String,
) -> Result<String, String> {
    let mut whisper = state.whisper.lock().await;
    whisper.transcribe(&audio_data, &language).map_err(|e| e.to_string())
}

#[tauri::command]
fn check_model_downloaded(app: AppHandle, model_size: String) -> Result<bool, String> {
    let app_data = app.path_resolver()
        .app_data_dir()
        .ok_or("Failed to get app data dir")?;

    let model_path = app_data.join("models").join(format!("ggml-{}.bin", model_size));
    Ok(model_path.exists())
}
```

### Frontend React - Gestion des Modes

**Settings UI:**
```tsx
// src/components/TranscriptionSettings.tsx

import { useState, useEffect } from 'react';
import { invoke } from '@tauri-apps/api/tauri';
import { listen } from '@tauri-apps/api/event';
import { Label } from '@/components/ui/label';
import { RadioGroup, RadioGroupItem } from '@/components/ui/radio-group';
import { Button } from '@/components/ui/button';
import { Progress } from '@/components/ui/progress';
import { Badge } from '@/components/ui/badge';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';

type TranscriptionMode = 'streaming' | 'local';
type ModelSize = 'tiny' | 'base' | 'small';

export function TranscriptionSettings() {
  const [mode, setMode] = useState<TranscriptionMode>('streaming');
  const [modelSize, setModelSize] = useState<ModelSize>('base');
  const [downloading, setDownloading] = useState(false);
  const [downloadProgress, setDownloadProgress] = useState(0);
  const [modelsDownloaded, setModelsDownloaded] = useState<Record<ModelSize, boolean>>({
    tiny: false,
    base: false,
    small: false,
  });

  // V√©rifier les mod√®les t√©l√©charg√©s au chargement
  useEffect(() => {
    checkDownloadedModels();
  }, []);

  // √âcouter le progress de t√©l√©chargement
  useEffect(() => {
    const unlisten = listen('download-progress', (event) => {
      setDownloadProgress(event.payload as number);
    });

    return () => {
      unlisten.then(fn => fn());
    };
  }, []);

  const checkDownloadedModels = async () => {
    const tiny = await invoke<boolean>('check_model_downloaded', { modelSize: 'tiny' });
    const base = await invoke<boolean>('check_model_downloaded', { modelSize: 'base' });
    const small = await invoke<boolean>('check_model_downloaded', { modelSize: 'small' });

    setModelsDownloaded({ tiny, base, small });
  };

  const handleDownloadModel = async (size: ModelSize) => {
    setDownloading(true);
    setDownloadProgress(0);

    try {
      await invoke('download_whisper_model', { modelSize: size });
      await checkDownloadedModels();
      // Basculer automatiquement vers le mode local
      setMode('local');
      setModelSize(size);
      await saveSettings({ mode: 'local', modelSize: size });
    } catch (error) {
      console.error('Download failed:', error);
      alert('√âchec du t√©l√©chargement. V√©rifiez votre connexion.');
    } finally {
      setDownloading(false);
    }
  };

  const handleModeChange = async (newMode: TranscriptionMode) => {
    // Si on bascule vers local mais aucun mod√®le n'est t√©l√©charg√©
    if (newMode === 'local' && !Object.values(modelsDownloaded).some(v => v)) {
      alert('Veuillez d\'abord t√©l√©charger un mod√®le IA.');
      return;
    }

    setMode(newMode);
    await saveSettings({ mode: newMode, modelSize });
  };

  const saveSettings = async (settings: { mode: TranscriptionMode; modelSize: ModelSize }) => {
    await invoke('save_transcription_settings', settings);
  };

  const modelInfo = {
    tiny: { size: '39 MB', quality: 'Correcte', speed: 'Tr√®s rapide (0.3s)' },
    base: { size: '74 MB', quality: 'Bonne', speed: 'Rapide (0.5s)' },
    small: { size: '244 MB', quality: 'Excellente', speed: 'Mod√©r√©e (1s)' },
  };

  return (
    <Card>
      <CardHeader>
        <CardTitle>Transcription</CardTitle>
        <CardDescription>
          Choisissez entre la transcription en streaming (temps r√©el) ou locale (offline)
        </CardDescription>
      </CardHeader>

      <CardContent className="space-y-6">
        {/* S√©lection du mode */}
        <div>
          <Label className="text-base font-semibold mb-3 block">Mode de transcription</Label>
          <RadioGroup value={mode} onValueChange={handleModeChange}>
            <div className="flex items-start space-x-3 p-3 border rounded-lg hover:bg-accent">
              <RadioGroupItem value="streaming" id="streaming" className="mt-1" />
              <div className="flex-1">
                <Label htmlFor="streaming" className="font-medium cursor-pointer">
                  Streaming en temps r√©el (Deepgram)
                  <Badge variant="default" className="ml-2">Recommand√©</Badge>
                </Label>
                <p className="text-sm text-muted-foreground mt-1">
                  ‚úÖ Texte qui d√©file pendant l'enregistrement<br/>
                  ‚úÖ Qualit√© excellente<br/>
                  ‚úÖ Aucun t√©l√©chargement requis<br/>
                  ‚ö†Ô∏è N√©cessite internet (~$0.004/min)
                </p>
              </div>
            </div>

            <div className="flex items-start space-x-3 p-3 border rounded-lg hover:bg-accent">
              <RadioGroupItem value="local" id="local" className="mt-1" />
              <div className="flex-1">
                <Label htmlFor="local" className="font-medium cursor-pointer">
                  Local offline (Whisper.cpp)
                </Label>
                <p className="text-sm text-muted-foreground mt-1">
                  ‚úÖ 100% gratuit et priv√©<br/>
                  ‚úÖ Fonctionne offline<br/>
                  ‚úÖ Ultra-rapide (0.3-1s)<br/>
                  ‚ö†Ô∏è Requiert t√©l√©chargement mod√®le IA (39-244 MB)
                </p>
              </div>
            </div>
          </RadioGroup>
        </div>

        {/* Configuration mode local */}
        {mode === 'local' && (
          <div className="space-y-3 pl-6 border-l-2 border-primary">
            <Label className="text-sm font-semibold">Mod√®le IA (qualit√© vs vitesse)</Label>

            {(['tiny', 'base', 'small'] as ModelSize[]).map((size) => (
              <div key={size} className="flex items-center justify-between p-3 border rounded-lg">
                <div className="flex-1">
                  <div className="flex items-center gap-2">
                    <span className="font-medium capitalize">{size}</span>
                    {modelsDownloaded[size] && (
                      <Badge variant="success">T√©l√©charg√©</Badge>
                    )}
                  </div>
                  <p className="text-xs text-muted-foreground mt-1">
                    {modelInfo[size].size} ‚Ä¢ Qualit√©: {modelInfo[size].quality} ‚Ä¢ Vitesse: {modelInfo[size].speed}
                  </p>
                </div>

                {!modelsDownloaded[size] ? (
                  <Button
                    size="sm"
                    onClick={() => handleDownloadModel(size)}
                    disabled={downloading}
                  >
                    T√©l√©charger
                  </Button>
                ) : (
                  <Button
                    size="sm"
                    variant={modelSize === size ? 'default' : 'outline'}
                    onClick={() => {
                      setModelSize(size);
                      saveSettings({ mode, modelSize: size });
                    }}
                  >
                    {modelSize === size ? 'Actif' : 'Utiliser'}
                  </Button>
                )}
              </div>
            ))}

            {downloading && (
              <div className="space-y-2 p-3 bg-accent rounded-lg">
                <p className="text-sm font-medium">T√©l√©chargement en cours...</p>
                <Progress value={downloadProgress} className="w-full" />
                <p className="text-xs text-muted-foreground">{downloadProgress}%</p>
              </div>
            )}
          </div>
        )}

        {/* Info carte API */}
        {mode === 'streaming' && (
          <div className="p-3 bg-blue-50 dark:bg-blue-950 border border-blue-200 dark:border-blue-800 rounded-lg">
            <p className="text-sm text-blue-900 dark:text-blue-100">
              üí° <strong>API Deepgram</strong>: 45 heures gratuites/mois incluses.
              Configuration dans Settings ‚Üí API Keys.
            </p>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
```

**Store Zustand (gestion d'√©tat):**
```tsx
// src/store/transcriptionStore.ts

import { create } from 'zustand';
import { invoke } from '@tauri-apps/api/tauri';

type TranscriptionMode = 'streaming' | 'local';

interface TranscriptionState {
  mode: TranscriptionMode;
  isRecording: boolean;
  interimText: string;
  finalText: string;

  setMode: (mode: TranscriptionMode) => void;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  setInterimText: (text: string) => void;
  setFinalText: (text: string) => void;
}

export const useTranscriptionStore = create<TranscriptionState>((set, get) => ({
  mode: 'streaming',
  isRecording: false,
  interimText: '',
  finalText: '',

  setMode: (mode) => set({ mode }),

  startRecording: async () => {
    const { mode } = get();
    set({ isRecording: true, interimText: '', finalText: '' });

    if (mode === 'streaming') {
      await invoke('start_streaming_transcription', { language: 'fr' });
    } else {
      await invoke('start_local_recording');
    }
  },

  stopRecording: async () => {
    const { mode } = get();
    set({ isRecording: false });

    if (mode === 'streaming') {
      await invoke('stop_streaming_transcription');
    } else {
      // Mode local: traitement post-enregistrement
      await invoke('stop_local_recording');
    }
  },

  setInterimText: (text) => set({ interimText: text }),
  setFinalText: (text) => set({ finalText: text, interimText: '' }),
}));
```

**Visualiseur avec texte live:**
```tsx
// src/components/TranscriptionVisualizer.tsx

import { useEffect } from 'react';
import { listen } from '@tauri-apps/api/event';
import { useTranscriptionStore } from '@/store/transcriptionStore';
import { motion, AnimatePresence } from 'framer-motion';

export function TranscriptionVisualizer() {
  const { mode, interimText, finalText, setInterimText, setFinalText } = useTranscriptionStore();

  useEffect(() => {
    // √âcouter les events de transcription
    const unlistenInterim = listen('transcription-interim', (event) => {
      setInterimText(event.payload as string);
    });

    const unlistenFinal = listen('transcription-final', (event) => {
      setFinalText(event.payload as string);
    });

    return () => {
      unlistenInterim.then(fn => fn());
      unlistenFinal.then(fn => fn());
    };
  }, []);

  return (
    <div className="p-6 space-y-4 min-h-[200px]">
      <div className="flex items-center gap-2">
        <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse" />
        <span className="text-sm font-medium">
          {mode === 'streaming' ? 'Streaming en temps r√©el' : 'Enregistrement local'}
        </span>
      </div>

      <div className="space-y-2">
        {/* Texte interim (streaming uniquement, gris√©) */}
        <AnimatePresence>
          {mode === 'streaming' && interimText && (
            <motion.p
              initial={{ opacity: 0, y: -10 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0 }}
              className="text-lg text-gray-400 italic"
            >
              {interimText}
            </motion.p>
          )}
        </AnimatePresence>

        {/* Texte final */}
        <AnimatePresence>
          {finalText && (
            <motion.p
              initial={{ opacity: 0, y: -10 }}
              animate={{ opacity: 1, y: 0 }}
              className="text-xl font-medium text-white"
            >
              {finalText}
            </motion.p>
          )}
        </AnimatePresence>

        {/* Placeholder si rien */}
        {!interimText && !finalText && (
          <p className="text-gray-500 text-center py-8">
            Commencez √† parler...
          </p>
        )}
      </div>
    </div>
  );
}
```

---

## üì¶ Structure de Distribution

### Exe Final

**Contenu embarqu√© dans l'exe (5-8 MB):**
```
voice-tool.exe
‚îú‚îÄ‚îÄ Frontend React compil√© (app.asar, ~2 MB)
‚îú‚îÄ‚îÄ Runtime Tauri (Rust, ~2 MB)
‚îú‚îÄ‚îÄ whisper.cpp binaire (libwhisper.dll, ~3 MB)
‚îî‚îÄ‚îÄ Pas de mod√®le IA embarqu√©
```

**Stockage utilisateur (%APPDATA%\VoiceTool\):**
```
%APPDATA%\VoiceTool\
‚îú‚îÄ‚îÄ models/                     # Mod√®les IA (t√©l√©charg√©s √† la demande)
‚îÇ   ‚îú‚îÄ‚îÄ ggml-tiny.bin          # 39 MB (optionnel)
‚îÇ   ‚îú‚îÄ‚îÄ ggml-base.bin          # 74 MB (optionnel)
‚îÇ   ‚îî‚îÄ‚îÄ ggml-small.bin         # 244 MB (optionnel)
‚îú‚îÄ‚îÄ recordings/                 # Audios enregistr√©s
‚îú‚îÄ‚îÄ user_settings.json          # Config utilisateur
‚îú‚îÄ‚îÄ history.json                # Historique des transcriptions
‚îî‚îÄ‚îÄ voice_tool.log              # Logs
```

### Formats de Distribution

1. **voice-tool.exe** - Portable standalone (~8 MB)
2. **voice-tool.msi** - Installeur Windows avec:
   - Int√©gration menu D√©marrer
   - Option "D√©marrer avec Windows"
   - D√©sinstallation propre

---

## üó∫Ô∏è Plan de Migration D√©taill√©

### Phase 0: Pr√©paration (1 jour)

**Objectif**: Setup environnement de d√©veloppement Tauri

**Tasks:**
1. Installer Rust + Tauri CLI
   ```bash
   # Windows
   winget install Rustlang.Rustup
   cargo install tauri-cli
   ```

2. Cr√©er le projet
   ```bash
   npm create tauri-app@latest voice-tool-v2
   # Choisir: React + TypeScript
   cd voice-tool-v2
   ```

3. Installer d√©pendances UI modernes
   ```bash
   npm install @radix-ui/react-* class-variance-authority clsx tailwind-merge
   npm install zustand lucide-react framer-motion
   npx shadcn-ui@latest init
   ```

4. Configurer Tailwind CSS
   ```bash
   npm install -D tailwindcss postcss autoprefixer
   npx tailwindcss init -p
   ```

5. Setup Rust dependencies dans `src-tauri/Cargo.toml`
   ```toml
   [dependencies]
   tauri = { version = "2.0", features = ["..." ] }
   serde = { version = "1", features = ["derive"] }
   serde_json = "1"
   tokio = { version = "1", features = ["full"] }
   anyhow = "1"

   # Audio
   cpal = "0.15"

   # Transcription
   whisper-rs = "0.12"  # Bindings whisper.cpp
   reqwest = { version = "0.11", features = ["stream"] }
   tokio-tungstenite = "0.21"  # WebSocket pour Deepgram

   # Hotkeys
   global-hotkey = "0.5"
   ```

**Livrable**: Projet Tauri vierge fonctionnel avec hot-reload

---

### Phase 1: Audio Capture (2-3 jours)

**Objectif**: Capture audio fonctionnelle avec visualisation

**Tasks:**

1. **Backend Rust - Capture audio**
   - Impl√©menter `src-tauri/src/audio.rs`
   - Utiliser `cpal` pour capturer depuis le micro
   - Buffer audio en m√©moire (format WAV, 16kHz mono)
   - Exposer Tauri commands: `start_recording()`, `stop_recording()`, `get_audio_devices()`

2. **Backend Rust - Visualisation temps r√©el**
   - Calculer RMS des chunks audio
   - √âmettre events `audio-level` vers le frontend (30 FPS)

3. **Frontend React - Visualiseur**
   - Composant `AudioVisualizer.tsx` avec canvas
   - Animation fluide des niveaux audio
   - Indicateur d'enregistrement (pulsation rouge)

4. **Frontend React - Contr√¥les**
   - Bouton micro (toggle on/off)
   - S√©lecteur de device audio (dropdown)
   - Store Zustand pour l'√©tat d'enregistrement

**Code exemple - Audio capture Rust:**
```rust
// src-tauri/src/audio.rs

use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use std::sync::{Arc, Mutex};

pub struct AudioRecorder {
    buffer: Arc<Mutex<Vec<i16>>>,
    stream: Option<cpal::Stream>,
    sample_rate: u32,
}

impl AudioRecorder {
    pub fn new() -> Self {
        Self {
            buffer: Arc::new(Mutex::new(Vec::new())),
            stream: None,
            sample_rate: 16000,
        }
    }

    pub fn start_recording(&mut self, device_index: Option<usize>) -> Result<()> {
        let host = cpal::default_host();
        let device = if let Some(idx) = device_index {
            host.input_devices()?.nth(idx).ok_or(anyhow!("Invalid device"))?
        } else {
            host.default_input_device().ok_or(anyhow!("No input device"))?
        };

        let config = device.default_input_config()?;
        let buffer = self.buffer.clone();

        let stream = device.build_input_stream(
            &config.into(),
            move |data: &[i16], _: &cpal::InputCallbackInfo| {
                let mut buf = buffer.lock().unwrap();
                buf.extend_from_slice(data);

                // Calculer RMS pour visualisation
                let rms = calculate_rms(data);
                // √âmettre via channel (√† impl√©menter)
                emit_audio_level(rms);
            },
            |err| eprintln!("Audio stream error: {}", err),
            None,
        )?;

        stream.play()?;
        self.stream = Some(stream);
        Ok(())
    }

    pub fn stop_recording(&mut self) -> Result<Vec<i16>> {
        if let Some(stream) = self.stream.take() {
            drop(stream);
        }

        let mut buffer = self.buffer.lock().unwrap();
        let audio_data = buffer.drain(..).collect();
        Ok(audio_data)
    }
}

fn calculate_rms(samples: &[i16]) -> f32 {
    let sum: f64 = samples.iter()
        .map(|&s| (s as f64 / 32768.0).powi(2))
        .sum();
    (sum / samples.len() as f64).sqrt() as f32
}
```

**Livrable**: Application avec bouton micro fonctionnel + visualisation audio

---

### Phase 2: Transcription Streaming (3-4 jours)

**Objectif**: Mode Deepgram streaming op√©rationnel

**Tasks:**

1. **Backend Rust - Deepgram WebSocket**
   - Impl√©menter `src-tauri/src/transcription/deepgram.rs`
   - Connexion WebSocket authentifi√©e
   - Envoi chunks audio en temps r√©el
   - R√©ception transcriptions (interim + final)
   - Gestion erreurs/reconnexion

2. **Backend Rust - Tauri Commands**
   - `start_streaming_transcription(language: String)`
   - `send_audio_chunk(chunk: Vec<i16>)`
   - `stop_streaming_transcription()`
   - Events: `transcription-interim`, `transcription-final`

3. **Frontend React - UI transcription live**
   - Composant `TranscriptionVisualizer.tsx`
   - Affichage texte interim (gris√©, italic)
   - Affichage texte final (blanc, bold)
   - Animations d'apparition (Framer Motion)

4. **Frontend React - Settings API**
   - Input pour cl√© API Deepgram
   - Validation de la cl√© (test call)
   - Stockage s√©curis√© dans user_settings.json

5. **Tests**
   - Latence moyenne (<300ms)
   - Qualit√© transcription (fran√ßais, anglais)
   - Robustesse (coupure r√©seau, reconnexion)

**Code exemple - Frontend React:**
```tsx
// src/hooks/useStreamingTranscription.ts

import { useEffect, useState } from 'react';
import { invoke } from '@tauri-apps/api/tauri';
import { listen } from '@tauri-apps/api/event';

export function useStreamingTranscription() {
  const [interimText, setInterimText] = useState('');
  const [finalText, setFinalText] = useState('');
  const [isStreaming, setIsStreaming] = useState(false);

  useEffect(() => {
    const unlistenInterim = listen('transcription-interim', (event) => {
      setInterimText(event.payload as string);
    });

    const unlistenFinal = listen('transcription-final', (event) => {
      setFinalText(prev => prev + ' ' + event.payload);
      setInterimText('');
    });

    return () => {
      unlistenInterim.then(fn => fn());
      unlistenFinal.then(fn => fn());
    };
  }, []);

  const startStreaming = async (language: string = 'fr') => {
    setFinalText('');
    setInterimText('');
    await invoke('start_streaming_transcription', { language });
    setIsStreaming(true);
  };

  const stopStreaming = async () => {
    await invoke('stop_streaming_transcription');
    setIsStreaming(false);
  };

  return {
    interimText,
    finalText,
    isStreaming,
    startStreaming,
    stopStreaming,
  };
}
```

**Livrable**: Mode streaming fonctionnel avec texte qui d√©file en temps r√©el

---

### Phase 3: Transcription Locale (3-4 jours)

**Objectif**: Mode whisper.cpp local op√©rationnel avec t√©l√©chargement de mod√®les

**Tasks:**

1. **Backend Rust - Whisper.cpp int√©gration**
   - D√©pendance `whisper-rs` dans Cargo.toml
   - Impl√©menter `src-tauri/src/transcription/whisper.rs`
   - Chargement mod√®le depuis AppData
   - Transcription audio (post-enregistrement)

2. **Backend Rust - T√©l√©chargement mod√®les**
   - Command `download_whisper_model(model_size: String)`
   - Stream depuis HuggingFace avec progress
   - Stockage dans `%APPDATA%\VoiceTool\models\`
   - Validation checksum (optionnel)

3. **Backend Rust - Tauri Commands**
   - `transcribe_with_whisper(audio: Vec<f32>, language: String)`
   - `check_model_downloaded(model_size: String) -> bool`
   - `get_downloaded_models() -> Vec<String>`

4. **Frontend React - Settings mod√®les**
   - UI de s√©lection mod√®le (tiny/base/small)
   - Boutons "T√©l√©charger" avec progress bar
   - Bascule mode streaming ‚Üî local
   - Indication mod√®les t√©l√©charg√©s (badges)

5. **Frontend React - Post-transcription**
   - Apr√®s arr√™t enregistrement ‚Üí "Traitement..."
   - Appel `transcribe_with_whisper()`
   - Affichage r√©sultat (animation d'apparition)

6. **Tests**
   - Vitesse transcription (objectif <1s pour 10s audio)
   - Qualit√© (comparaison avec Deepgram)
   - Consommation m√©moire

**Code exemple - T√©l√©chargement mod√®le:**
```rust
// src-tauri/src/transcription/model_downloader.rs

use reqwest::Client;
use futures_util::StreamExt;
use std::fs::File;
use std::io::Write;
use std::path::PathBuf;

pub async fn download_model(
    model_size: &str,
    dest_path: PathBuf,
    progress_callback: impl Fn(u64, u64),
) -> Result<()> {
    let url = format!(
        "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-{}.bin",
        model_size
    );

    let client = Client::new();
    let response = client.get(&url).send().await?;
    let total_size = response.content_length().unwrap_or(0);

    let mut file = File::create(dest_path)?;
    let mut downloaded: u64 = 0;
    let mut stream = response.bytes_stream();

    while let Some(chunk) = stream.next().await {
        let chunk = chunk?;
        file.write_all(&chunk)?;
        downloaded += chunk.len() as u64;
        progress_callback(downloaded, total_size);
    }

    Ok(())
}
```

**Livrable**: Mode local fonctionnel avec t√©l√©chargement de mod√®les

---

### Phase 4: Features Compl√©mentaires (2-3 jours)

**Objectif**: Parit√© fonctionnelle avec app Python

**Tasks:**

1. **Hotkeys globaux**
   - Int√©gration `global-hotkey` (Rust)
   - Command `register_hotkey(keys: String, action: String)`
   - Actions: `toggle_recording`, `open_window`
   - UI de configuration (key binding input)

2. **System Tray**
   - Plugin `tauri-plugin-system-tray`
   - Ic√¥ne + menu contextuel
   - Actions: Ouvrir, Settings, Quitter
   - Indicateur d'enregistrement (ic√¥ne rouge)

3. **Historique**
   - Stockage JSON dans AppData
   - Composant `History.tsx` (liste d√©roulante)
   - Actions: Copier, Supprimer, Rejouer audio

4. **Clipboard auto-paste**
   - Copie automatique apr√®s transcription
   - Option "Coller au curseur" (simulation Ctrl+V)
   - Cross-platform (Windows/macOS/Linux)

5. **Param√®tres persistants**
   - user_settings.json dans AppData
   - Migration depuis ancien format (si applicable)
   - Validation et defaults

**Livrable**: Application feature-complete

---

### Phase 5: Polish & Distribution (2 jours)

**Objectif**: Application production-ready

**Tasks:**

1. **UI/UX Polish**
   - Animations fluides (Framer Motion)
   - Dark mode (syst√®me ou manuel)
   - Responsive design
   - Error states et loading indicators

2. **Gestion d'erreurs**
   - Toasts notifications (shadcn/ui)
   - Fallbacks (mode streaming √©choue ‚Üí sugg√©rer mode local)
   - Logs d√©taill√©s (fichier + console)

3. **Build & Packaging**
   - Optimisation bundle (tree-shaking)
   - G√©n√©ration ic√¥nes (multi-r√©solutions)
   - Configuration tauri.conf.json (identifiers, permissions)
   - Build .exe + .msi

4. **CI/CD**
   - GitHub Actions pour build automatique
   - Release workflow (tags ‚Üí artifacts)
   - Code signing (optionnel, certificat Windows)

5. **Documentation**
   - README.md complet
   - Guide d'installation
   - FAQ et troubleshooting

**Commandes de build:**
```bash
# Dev
npm run tauri dev

# Build production (local)
npm run tauri build

# Output dans src-tauri/target/release/bundle/
# - msi/voice-tool.msi
# - nsis/voice-tool-setup.exe
```

**Livrable**: Exe distributable + CI/CD op√©rationnel

---

## üìä Estimations Totales

| Phase | Dur√©e | Complexit√© |
|-------|-------|------------|
| Phase 0: Setup | 1 jour | Facile |
| Phase 1: Audio | 2-3 jours | Moyenne |
| Phase 2: Streaming | 3-4 jours | Difficile |
| Phase 3: Local | 3-4 jours | Moyenne |
| Phase 4: Features | 2-3 jours | Facile |
| Phase 5: Polish | 2 jours | Facile |
| **TOTAL** | **13-17 jours** | - |

**Estimation r√©aliste avec buffer**: **3-4 semaines**

---

## üéØ Crit√®res de Succ√®s

### Fonctionnels
- ‚úÖ Exe standalone <10 MB (sans mod√®les)
- ‚úÖ Startup <1s
- ‚úÖ Mode streaming avec latence <300ms
- ‚úÖ Mode local avec transcription <1s (audio 10s)
- ‚úÖ Bascule fluide entre modes
- ‚úÖ Hotkeys globaux fonctionnels
- ‚úÖ System tray op√©rationnel
- ‚úÖ Historique persistant

### Techniques
- ‚úÖ Architecture propre (s√©paration frontend/backend)
- ‚úÖ Code TypeScript + Rust type-safe
- ‚úÖ Tests unitaires critiques (audio, transcription)
- ‚úÖ Logs structur√©s
- ‚úÖ Gestion d'erreurs robuste

### Distribution
- ‚úÖ Build automatis√© (CI/CD)
- ‚úÖ .msi installer professionnel
- ‚úÖ Documentation compl√®te

---

## üîÑ Comparaison Avant/Apr√®s

| Aspect | Avant (Python/Tkinter) | Apr√®s (Tauri/React) |
|--------|------------------------|---------------------|
| **Taille exe** | 80-150 MB | 5-50 MB |
| **Startup** | 2-4s | <1s |
| **UI** | Tkinter (vieillot) | React moderne |
| **Hot reload** | ‚ùå | ‚úÖ |
| **Transcription** | API lente (2-4s) | Streaming (<300ms) ou local (<1s) |
| **Co√ªt** | $0.006/min | $0.004/min ou gratuit |
| **Offline** | ‚ùå | ‚úÖ (mode local) |
| **Crashes** | Fr√©quents (PortAudio) | Rares (Rust stable) |
| **Maintenabilit√©** | Difficile (1500+ lignes) | Facile (modularis√©) |
| **CI/CD** | Basique | Complet (auto-release) |

---

## üìö Ressources & R√©f√©rences

### Documentation
- [Tauri Docs](https://tauri.app/v2/)
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
- [whisper-rs](https://github.com/tazz4843/whisper-rs)
- [Deepgram Streaming API](https://developers.deepgram.com/docs/streaming)
- [shadcn/ui Components](https://ui.shadcn.com/)
- [cpal Audio Library](https://docs.rs/cpal/)

### Exemples de code
- [Tauri + React Template](https://github.com/tauri-apps/tauri/tree/dev/examples/api)
- [whisper-rs Examples](https://github.com/tazz4843/whisper-rs/tree/master/examples)

### APIs
- [Deepgram](https://deepgram.com/) - 45h gratuit/mois
- [HuggingFace Whisper Models](https://huggingface.co/ggerganov/whisper.cpp)

---

## ‚ö†Ô∏è Points d'Attention

### D√©pendances
- **WebView2** (Windows): Pr√©-install√© sur Win10/11 r√©cent. Si absent, popup d'installation (100 MB, une fois).
- **Mod√®les Whisper**: T√©l√©chargement uniquement si mode local activ√©.

### Performance
- **GPU**: whisper.cpp b√©n√©ficie du GPU (CUDA/Metal) pour 10x vitesse. D√©tecter automatiquement.
- **RAM**: Mode local consomme ~500 MB (mod√®le charg√© en m√©moire). Acceptable pour usage desktop.

### S√©curit√©
- **API Keys**: Stocker dans user_settings.json (plaintext local). Pour production avanc√©e, utiliser OS keychain (optionnel).
- **Audio**: Jamais stock√© permanent (sauf option "Garder enregistrements").

### Limitations
- **Streaming local**: whisper.cpp ne supporte pas nativement le streaming. Possible avec chunking mais qualit√© moindre.
- **Langues rares**: Deepgram supporte 30+ langues vs 90+ pour Whisper.

---

## üöÄ Next Steps (Apr√®s Migration)

### Am√©liorations Futures
1. **Auto-update int√©gr√©** (tauri-plugin-updater)
2. **Multi-langues UI** (i18n)
3. **Th√®mes personnalisables**
4. **Export formats** (TXT, MD, JSON)
5. **Int√©grations** (Notion, Obsidian, etc.)
6. **Mode dict√©e longue** (enregistrements >5min avec chunking)
7. **Commandes vocales** (meta-actions: "annuler", "nouveau paragraphe")

### Expansion Plateforme
- **macOS**: Build .dmg (d√©j√† support√© par Tauri)
- **Linux**: Build .AppImage / .deb
- **Mobile** (futur): Tauri supporte iOS/Android (beta)

---

## üìû Support & Questions

Pour toute question durant la migration:
1. R√©f√©rer √† cette spec
2. Consulter la doc Tauri/whisper-rs
3. Tester progressivement (une phase √† la fois)
4. Logger abondamment (Rust: `tracing`, React: `console.log`)

**Bonne migration ! üéâ**
